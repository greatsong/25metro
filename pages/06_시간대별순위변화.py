import io
import re
import streamlit as st
import pandas as pd
import plotly.express as px

st.set_page_config(page_title="ì§€í•˜ì²  ë ˆì´ì‹± ì°¨íŠ¸", layout="wide")

# =========================
# ìœ í‹¸: CSV ì½ê¸° (ì¸ì½”ë”© ìë™ ì‹œë„)
# =========================
def _read_csv_any_encoding(src, dtype_spec):
    def _read(reader):
        # cp949 -> utf-8-sig ìˆœì„œë¡œ ì‹œë„
        try:
            return pd.read_csv(reader, encoding="cp949", dtype=dtype_spec)
        except UnicodeDecodeError:
            if hasattr(reader, "seek"):
                reader.seek(0)
            return pd.read_csv(reader, encoding="utf-8-sig", dtype=dtype_spec)

    # íŒŒì¼ ê²½ë¡œë‚˜ íŒŒì¼ê°ì²´/ë°”ì´íŠ¸ ëª¨ë‘ ì§€ì›
    if isinstance(src, (str, bytes, bytearray)):
        return _read(src)
    elif hasattr(src, "read"):  # file-like
        return _read(src)
    else:  # ë°”ì´íŠ¸(ë©”ëª¨ë¦¬)ë¼ë©´ BytesIOë¡œ ê°ì‹¸ê¸°
        return _read(io.BytesIO(src))

# =========================
# ì „ì²˜ë¦¬ í•µì‹¬: ê²¬ê³ í•œ ì»¬ëŸ¼ íŒŒì‹±
# =========================
def _parse_hour(raw_col: str) -> str | None:
    """
    í—¤ë”ì—ì„œ 'ì‹œê°„'ì„ ì¶”ì¶œí•´ 2ìë¦¬ë¡œ ë°˜í™˜. (ì˜ˆ: '04', '18')
    í—ˆìš© ì˜ˆ: '04:00~05:00 ìŠ¹ì°¨', '04ì‹œ-05ì‹œ í•˜ì°¨', '04ì‹œ ìŠ¹ì°¨', '04 ~ 05 ìŠ¹ì°¨'
    """
    s = str(raw_col)
    # ìš°ì„  ':' ë˜ëŠ” 'ì‹œ' ì•ì˜ ìˆ«ì 1~2ìë¦¬
    m = re.search(r'(\d{1,2})(?=[:ì‹œ])', s)
    if not m:
        # ë°±ì—…: ì‹œì‘ ë¶€ë¶„ì˜ 1~2ìë¦¬ ìˆ«ì
        m = re.search(r'(^|\s)(\d{1,2})(?=\D)', s)
        if m:
            hh = int(m.group(2))
        else:
            return None
    else:
        hh = int(m.group(1))
    if 0 <= hh <= 23:
        return f"{hh:02d}"
    return None

def _rename_columns_safely(df: pd.DataFrame) -> pd.DataFrame:
    base = ['ì‚¬ìš©ì›”', 'í˜¸ì„ ëª…', 'ì—­ID', 'ì§€í•˜ì² ì—­']
    new_cols = []
    keep_mask = []

    for c in df.columns:
        c_str = str(c).strip()
        if c_str in base:
            new_cols.append(c_str)
            keep_mask.append(True)
            continue

        # ìŠ¹ì°¨/í•˜ì°¨ ì»¬ëŸ¼ë§Œ ì¶”ë¦¼
        if ('ìŠ¹ì°¨' in c_str) or ('í•˜ì°¨' in c_str):
            hh = _parse_hour(c_str)
            if hh is not None:
                gu = 'ìŠ¹ì°¨' if 'ìŠ¹ì°¨' in c_str else 'í•˜ì°¨'
                new_cols.append(f"{hh}_{gu}")
                keep_mask.append(True)
                continue

        # ê·¸ ì™¸ëŠ” ì œê±°
        new_cols.append(None)
        keep_mask.append(False)

    df = df.loc[:, keep_mask].copy()
    df.columns = [c for c in new_cols if c is not None]
    return df

# =========================
# ë°ì´í„° ë¡œë”© + ì „ì²˜ë¦¬ (ìºì‹œ)
# =========================
@st.cache_data(show_spinner=False)
def load_and_prep_data(file_bytes: bytes | None, source_hint: str | None):
    """
    CSVë¥¼ ë¡œë“œ í›„:
      - ë¶ˆí•„ìš” ì—´ ì œê±°(íŒ¨í„´ ê¸°ë°˜)
      - ì‹œê°„/ìŠ¹í•˜ì°¨ ì»¬ëŸ¼ í‘œì¤€í™”(04_ìŠ¹ì°¨ ë“±)
      - ìˆ«ì ë³€í™˜
      - long í¬ë§· ë³€í™˜
    ë°˜í™˜: df_long (ì»¬ëŸ¼: ì§€í•˜ì² ì—­, í˜¸ì„ ëª…, ì‚¬ìš©ì›”?, ì‹œê°„ëŒ€, êµ¬ë¶„, ì¸ì›ìˆ˜)
    """
    dtype_spec = {'í˜¸ì„ ëª…': 'string', 'ì§€í•˜ì² ì—­': 'string', 'ì—­ID': 'string', 'ì‚¬ìš©ì›”': 'string'}

    df = None
    # 1) ì—…ë¡œë“œ íŒŒì¼ ìš°ì„ 
    if file_bytes is not None:
        df = _read_csv_any_encoding(io.BytesIO(file_bytes), dtype_spec)
    else:
        # 2) í´ë°± ê²½ë¡œ ì‹œë„
        for path in ["/mnt/data/ì§€í•˜ì² ë°ì´í„°.csv", "ì§€í•˜ì² ë°ì´í„°.csv"]:
            try:
                df = _read_csv_any_encoding(path, dtype_spec)
                break
            except FileNotFoundError:
                continue

    if df is None:
        st.error("ğŸ˜¥ CSVë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ `/mnt/data` ë˜ëŠ” ì•± í´ë”ì— `ì§€í•˜ì² ë°ì´í„°.csv`ë¥¼ ë‘ì„¸ìš”.")
        return None

    # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸(ì§€í•˜ì² ì—­ì€ ìµœì†Œ í•„ìš”)
    if 'ì§€í•˜ì² ì—­' not in df.columns:
        st.error("ë°ì´í„°ì— 'ì§€í•˜ì² ì—­' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. í—¤ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

    # ê²°ì¸¡ ì œê±°(í•µì‹¬ ì‹ë³„)
    key_cols = [c for c in ['í˜¸ì„ ëª…', 'ì§€í•˜ì² ì—­'] if c in df.columns]
    if key_cols:
        df.dropna(subset=key_cols, inplace=True)

    # ì•ˆì „í•œ ì»¬ëŸ¼ í‘œì¤€í™”
    df = _rename_columns_safely(df)

    # value ì»¬ëŸ¼(ìŠ¹/í•˜ì°¨) ìˆ«ì ë³€í™˜
    value_cols = [c for c in df.columns if c.endswith('_ìŠ¹ì°¨') or c.endswith('_í•˜ì°¨')]
    if not value_cols:
        st.error("ì‹œê°„ëŒ€ ìŠ¹/í•˜ì°¨ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í—¤ë” í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None

    for col in value_cols:
        df[col] = (
            pd.to_numeric(
                df[col].astype(str).str.replace(',', '', regex=False),
                errors='coerce'
            ).fillna(0).astype('int64')
        )

    # id_varsëŠ” ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    id_candidates = ['ì‚¬ìš©ì›”', 'í˜¸ì„ ëª…', 'ì—­ID', 'ì§€í•˜ì² ì—­']
    id_vars = [c for c in id_candidates if c in df.columns]

    df_long = df.melt(id_vars=id_vars, var_name='ì‹œê°„êµ¬ë¶„', value_name='ì¸ì›ìˆ˜')
    df_long['ì‹œê°„ëŒ€'] = df_long['ì‹œê°„êµ¬ë¶„'].str.split('_').str[0]
    df_long['êµ¬ë¶„'] = df_long['ì‹œê°„êµ¬ë¶„'].str.split('_').str[1]
    df_long.drop(columns=['ì‹œê°„êµ¬ë¶„'], inplace=True)

    # íƒ€ì… ì •ë¦¬
    df_long['ì‹œê°„ëŒ€'] = df_long['ì‹œê°„ëŒ€'].astype('string')
    df_long['êµ¬ë¶„'] = df_long['êµ¬ë¶„'].astype('string')
    if 'í˜¸ì„ ëª…' in df_long.columns:
        df_long['í˜¸ì„ ëª…'] = df_long['í˜¸ì„ ëª…'].astype('string')
    df_long['ì§€í•˜ì² ì—­'] = df_long['ì§€í•˜ì² ì—­'].astype('string')

    return df_long

# =========================
# ëˆ„ì /ê·¸ë£¹ ê³„ì‚° (ìºì‹œ)
# =========================
@st.cache_data(show_spinner=False)
def get_cumulative_data(df_long: pd.DataFrame, combine_stations: bool, analysis_type: str):
    """
    analysis_type: 'ì¢…í•©' | 'ìŠ¹ì°¨' | 'í•˜ì°¨'
    combine_stations: True â†’ í™˜ìŠ¹ì—­ í•©ì‚°(í˜¸ì„  ë¬´ì‹œ)
    """
    if analysis_type != 'ì¢…í•©':
        df_filtered = df_long[df_long['êµ¬ë¶„'] == analysis_type]
    else:
        df_filtered = df_long

    # ë ˆì´ë¸” ìƒì„±ìš©: í˜¸ì„ ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì—­ëª…ë§Œ ì‚¬ìš©
    has_line = 'í˜¸ì„ ëª…' in df_filtered.columns

    if combine_stations or not has_line:
        grouped = df_filtered.groupby(['ì‹œê°„ëŒ€', 'ì§€í•˜ì² ì—­'], as_index=False)['ì¸ì›ìˆ˜'].sum()
        grouped['ì—­ëª…(í˜¸ì„ )'] = grouped['ì§€í•˜ì² ì—­']
    else:
        grouped = df_filtered.groupby(['ì‹œê°„ëŒ€', 'í˜¸ì„ ëª…', 'ì§€í•˜ì² ì—­'], as_index=False)['ì¸ì›ìˆ˜'].sum()
        grouped['ì—­ëª…(í˜¸ì„ )'] = grouped['ì§€í•˜ì² ì—­'] + "(" + grouped['í˜¸ì„ ëª…'] + ")"

    # ì‹œê°„ëŒ€ ì •ë ¬: 04~23 â†’ 00~03 (ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ê°’ë§Œ)
    seen = pd.unique(grouped['ì‹œê°„ëŒ€']).tolist()
    desired = [f"{h:02d}" for h in range(4, 24)] + [f"{h:02d}" for h in range(0, 4)]
    order = [t for t in desired if t in seen]
    if not order:  # ì „ë¶€ ë¯¸ì¼ì¹˜í•˜ë©´ ë“±ì¥ìˆœ ìœ ì§€
        order = seen

    grouped['ì‹œê°„ëŒ€'] = pd.Categorical(grouped['ì‹œê°„ëŒ€'], categories=order, ordered=True)
    grouped.sort_values(['ì—­ëª…(í˜¸ì„ )', 'ì‹œê°„ëŒ€'], inplace=True)

    grouped['ëˆ„ì ì¸ì›ìˆ˜'] = grouped.groupby('ì—­ëª…(í˜¸ì„ )', sort=False)['ì¸ì›ìˆ˜'].cumsum()
    return grouped

# =========================
# UI
# =========================
st.header("ğŸ ì‹œê°„ëŒ€ë³„ ëˆ„ì  ìœ ë™ì¸êµ¬ ë ˆì´ì‹± ì°¨íŠ¸")
st.markdown("ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ê° ì—­ì˜ **ëˆ„ì ** ìŠ¹Â·í•˜ì°¨ ì¸ì› ìˆœìœ„ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ í™•ì¸í•´ìš”.")

uploaded = st.file_uploader("CSV ì—…ë¡œë“œ (ì§€í•˜ì² ë°ì´í„°.csv)", type=["csv"])
file_bytes = uploaded.getvalue() if uploaded is not None else None
source_hint = uploaded.name if uploaded is not None else None

df_long = load_and_prep_data(file_bytes, source_hint)

if df_long is None:
    st.stop()

# ì˜µì…˜
combine_stations = st.checkbox("ğŸ” ë™ì¼ ì—­ëª… ë°ì´í„° í•©ì‚°", help="ì²´í¬ ì‹œ, í™˜ìŠ¹ì—­(ì—¬ëŸ¬ í˜¸ì„ ) ë°ì´í„°ë¥¼ ì—­ëª… ê¸°ì¤€ìœ¼ë¡œ í•©ì‚°í•©ë‹ˆë‹¤.")
analysis_type = st.radio("ğŸ“ˆ ë¶„ì„ ê¸°ì¤€ ì„ íƒ", ('ì¢…í•©', 'ìŠ¹ì°¨', 'í•˜ì°¨'), horizontal=True, index=0)
top_n = st.slider("ğŸ“Š í‘œì‹œí•  ìˆœìœ„ (TOP N)", 5, 30, 10)
animation_speed = st.slider(
    "ğŸ’¨ ì• ë‹ˆë©”ì´ì…˜ ì†ë„ (ms/í”„ë ˆì„)", min_value=100, max_value=1000, value=300, step=50,
    help="ê°’ì´ ë‚®ì„ìˆ˜ë¡ ë” ë¹ ë¥´ê²Œ ì§„í–‰ë©ë‹ˆë‹¤."
)

# ê³„ì‚°
cumulative_data = get_cumulative_data(df_long, combine_stations, analysis_type)

# TOP N ì¶”ë¦¬ê¸°: rank ë°©ì‹(ë¹ ë¥´ê³  ê²½ê³  ì—†ìŒ)
animation_data = cumulative_data.copy()
animation_data['rank'] = animation_data.groupby('ì‹œê°„ëŒ€')['ëˆ„ì ì¸ì›ìˆ˜'].rank(method='first', ascending=False)
animation_data = animation_data[animation_data['rank'] <= top_n].drop(columns='rank')

st.markdown("---")
st.info("â–¶ï¸ ì•„ë˜ ê·¸ë˜í”„ì˜ ì¬ìƒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œê°„ëŒ€ë³„ **ëˆ„ì ** ìˆœìœ„ ë³€í™”ë¥¼ í™•ì¸í•˜ì„¸ìš”!")

# ì°¨íŠ¸
fig = px.bar(
    animation_data,
    x="ëˆ„ì ì¸ì›ìˆ˜",
    y="ì—­ëª…(í˜¸ì„ )",
    orientation="h",
    color="ì—­ëª…(í˜¸ì„ )",
    animation_frame="ì‹œê°„ëŒ€",
    animation_group="ì—­ëª…(í˜¸ì„ )",
    text="ëˆ„ì ì¸ì›ìˆ˜",
    title=f"ì‹œê°„ëŒ€ë³„ ëˆ„ì  {analysis_type} ì¸ì› TOP {top_n} ë ˆì´ì‹± ì°¨íŠ¸"
)

# ì¶•/ë ˆì´ì•„ì›ƒ
fig.update_layout(
    xaxis_title="ëˆ„ì  ì¸ì›ìˆ˜",
    yaxis_title="ì§€í•˜ì² ì—­",
    showlegend=False,
    height=640,
)
fig.update_traces(texttemplate='%{x:,.0f}', textposition='outside')

# xì¶• ìµœëŒ€ì¹˜ ì—¬ìœ 
max_value = animation_data['ëˆ„ì ì¸ì›ìˆ˜'].max() if not animation_data.empty else 0
fig.update_xaxes(range=[0, max_value * 1.2 if max_value > 0 else 1])

# ì• ë‹ˆë©”ì´ì…˜ ì†ë„ ì•ˆì „ ì ìš©
try:
    if getattr(fig.layout, "updatemenus", None) and len(fig.layout.updatemenus) > 0:
        btn_args = fig.layout.updatemenus[0].buttons[0].args[1]
        if "frame" in btn_args:
            btn_args["frame"]["duration"] = int(animation_speed)
        if "transition" in btn_args:
            btn_args["transition"]["duration"] = int(animation_speed * 0.3)

    if getattr(fig.layout, "sliders", None) and len(fig.layout.sliders) > 0:
        fig.layout.sliders[0]["transition"]["duration"] = int(animation_speed * 0.3)
except Exception:
    pass  # ì¼ë¶€ Plotly ë²„ì „ì—ì„œ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì¡°ìš©íˆ ë¬´ì‹œ

st.plotly_chart(fig, use_container_width=True)
