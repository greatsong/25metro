import streamlit as st
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler

# ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (ëª¨ë“  í˜ì´ì§€ì—ì„œ ìºì‹œ ê³µìœ )
@st.cache_data
def load_data():
    dtype_spec = {'í˜¸ì„ ëª…': str, 'ì§€í•˜ì² ì—­': str}
    try:
        df = pd.read_csv('ì§€í•˜ì² ë°ì´í„°.csv', encoding='cp949', dtype=dtype_spec)
    except UnicodeDecodeError:
        df = pd.read_csv('ì§€í•˜ì² ë°ì´í„°.csv', encoding='utf-8-sig', dtype=dtype_spec)
    except FileNotFoundError:
        st.error("ğŸ˜¥ 'ì§€í•˜ì² ë°ì´í„°.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return None
    
    df.dropna(subset=['í˜¸ì„ ëª…', 'ì§€í•˜ì² ì—­'], inplace=True)
    return df

# ì›ë³¸ ë°ì´í„° ë¡œë“œ
df_raw = load_data()

st.header("ğŸ“Š ë‚˜ì™€ ë¹„ìŠ·í•œ ì—­ì€ ì–´ë””ì¼ê¹Œ?")
st.markdown("ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ íŒ¨í„´ì„ ê¸°ì¤€ìœ¼ë¡œ, ì„ íƒí•œ ì—­ê³¼ ê°€ì¥ ìœ ì‚¬í•œ íŒ¨í„´ì„ ë³´ì´ëŠ” ì—­ 3ê³³ì„ ì°¾ì•„ë´…ë‹ˆë‹¤.")

if df_raw is not None:
    combine_stations = st.checkbox("ğŸ” ë™ì¼ ì—­ëª… ë°ì´í„° í•©ì‚°", help="ì²´í¬ ì‹œ, ëª¨ë“  í˜¸ì„ ì˜ ë°ì´í„°ë¥¼ í•©ì‚°í•˜ì—¬ ì—­ë³„ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    # ë°ì´í„° ì „ì²˜ë¦¬ ë° íŒ¨í„´ ìƒì„± (ì˜µì…˜ì— ë”°ë¼ ë™ì  ì²˜ë¦¬)
    @st.cache_data
    def get_pattern_data(_df, _combine):
        df = _df.iloc[:, :-1]
        id_vars = ['ì‚¬ìš©ì›”', 'í˜¸ì„ ëª…', 'ì—­ID', 'ì§€í•˜ì² ì—­']
        if _combine:
            # í˜¸ì„ ëª…, ì—­ID ì œì™¸í•˜ê³  ì—­ëª…ìœ¼ë¡œë§Œ ì§‘ê³„
            value_vars = [c for c in df.columns if c not in id_vars]
            df = df.groupby('ì§€í•˜ì² ì—­')[value_vars].sum().reset_index()
            id_vars = ['ì§€í•˜ì² ì—­']
        
        col_names = id_vars[:]
        for i in range(len(id_vars), len(df.columns), 2):
            time_str = df.columns[i].split('~')[0][:2]
            col_names.append(f'{time_str}_ìŠ¹ì°¨')
            col_names.append(f'{time_str}_í•˜ì°¨')
        df.columns = col_names

        value_cols = [c for c in df.columns if '_ìŠ¹ì°¨' in c or '_í•˜ì°¨' in c]
        for col in value_cols:
            if df[col].dtype == 'object':
                df[col] = pd.to_numeric(df[col].str.replace(',', ''), errors='coerce').fillna(0).astype(int)
            else:
                df[col] = df[col].fillna(0).astype(int)

        if _combine:
            df_wide = df.set_index('ì§€í•˜ì² ì—­')
        else:
            df_wide = df.set_index(['í˜¸ì„ ëª…', 'ì§€í•˜ì² ì—­'])
        
        scaler = MinMaxScaler()
        df_normalized = pd.DataFrame(scaler.fit_transform(df_wide), index=df_wide.index, columns=df_wide.columns)
        return df_normalized

    df_pattern_normalized = get_pattern_data(df_raw.copy(), combine_stations)
    
    if combine_stations:
        station_list = sorted(df_pattern_normalized.index.tolist())
        format_func = lambda x: x
    else:
        station_list = sorted(df_pattern_normalized.index.to_list())
        format_func = lambda x: f"{x[1]} ({x[0]})"
        
    selected_station = st.selectbox(
        'ê¸°ì¤€ì´ ë  ì—­ì„ ì„ íƒí•˜ì„¸ìš”.',
        station_list,
        format_func=format_func
    )

    similarity_matrix = cosine_similarity(df_pattern_normalized)
    similarity_df = pd.DataFrame(similarity_matrix, index=df_pattern_normalized.index, columns=df_pattern_normalized.index)

    if selected_station:
        similar_stations = similarity_df[selected_station].sort_values(ascending=False).iloc[1:4]
        st.subheader(f"ğŸ“ˆ '{format_func(selected_station)}' ì—­ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì—­ TOP 3")
        
        for station, score in similar_stations.items():
            st.markdown(f"##### **{format_func(station)}** (ìœ ì‚¬ë„: {score:.2f})")
